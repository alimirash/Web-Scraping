{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# import gc\n",
    "\n",
    "stock_data = pd.read_csv('TOP_100_Stock_Name.csv', encoding='latin-1' , header=None)\n",
    "\n",
    "type_of_data = 'dividend-yield-history'\n",
    "urls = []\n",
    "for i in range(1, len(stock_data)):\n",
    "    urls.append('https://www.macrotrends.net/stocks/charts/' + str(stock_data[1][i]) + '/' + str(stock_data[0][i]) + '/' + str(type_of_data))\n",
    "\n",
    "def parse_page(driver):\n",
    "    driver.execute_script(\"window.scrollTo(0 , 1000)\")\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # g tag with this XPath : //*[@id=\"chartdiv\"]/div/div/div[2]/div[3]/div/div/svg/g[12]/g\n",
    "    # find div tag with this class name : amChartsPanel amcharts-stock-panel-div amcharts-stock-panel-div-stockPanel2\n",
    "    main_div = soup.find_all('div', class_='amChartsPanel amcharts-stock-panel-div amcharts-stock-panel-div-stockPanel2')\n",
    "    # find inner div tag with this class name : amcharts-chart-div\n",
    "    inner_div = main_div[0].find_all('div', class_='amcharts-chart-div')\n",
    "    # find g tag with this XPath : //*[@id=\"chartdiv\"]/div/div/div[2]/div[3]/div/div/svg/g[12]/g\n",
    "    g_tag = inner_div[0].find_all('g')[12]\n",
    "    # find all circle tags\n",
    "    circles = g_tag.find_all('circle')\n",
    "    # Extract and print the aria-label attributes\n",
    "    aria_labels = [circle['aria-label'] for circle in circles if 'aria-label' in circle.attrs]\n",
    "    print(aria_labels)\n",
    "\n",
    "    # save the data to a list\n",
    "    data = []\n",
    "    for label in aria_labels:\n",
    "        data.append(label.split(' ')[0])\n",
    "    return data\n",
    "    \n",
    "\n",
    "\n",
    "for count, url in enumerate(urls):\n",
    "    filename = f'{type_of_data}\\{stock_data[1][count + 1]}_{type_of_data}_Year_Dividend_history.csv'\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(filename):\n",
    "        try: \n",
    "            time.sleep(2)\n",
    "            chrome_options = webdriver.ChromeOptions()\n",
    "            chrome_options.add_argument('--ignore-certificate-errors')\n",
    "            chrome_options.add_argument('--disable-web-security')\n",
    "            chrome_options.add_argument('--allow-running-insecure-content')\n",
    "            driver = webdriver.Chrome()\n",
    "            driver.implicitly_wait(4)\n",
    "            driver.get(url)\n",
    "            driver.maximize_window()\n",
    "            # Wait for the page to load\n",
    "            element = WebDriverWait(driver, 2).until(\n",
    "                EC.presence_of_element_located((By.ID, \"main_content\"))\n",
    "            )\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"Button__StyledButton-a1qza5-0.jkvvVr\"))).click()\n",
    "                print('Click Accept All Button')\n",
    "            except:\n",
    "                print(\"No cookie consent pop-up found or failed to click 'Accept all'.\")\n",
    "        \n",
    "            # Get the page source\n",
    "            data = parse_page(driver)\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            # Save the DataFrame to a CSV file\n",
    "            df.to_csv(f'{type_of_data}\\{stock_data[1][count + 1]}_{type_of_data}_Year_Dividend_history.csv', index=False , header=None)\n",
    "            print(\"Save \" + str(stock_data[1][count + 1]) + f\" On {type_of_data}\")\n",
    "            # Close the browser\n",
    "            driver.quit()\n",
    "        except:\n",
    "            print(\"Error On \" + str(stock_data[1][count + 1]))\n",
    "            driver.quit()\n",
    "    else:\n",
    "        print(stock_data[0][count + 1] + f\"_{type_of_data}\" + \" already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request error: 403 Client Error: Forbidden for url: https://www.macrotrends.net/stocks/charts/LIN/linde/dividend-yield-history\n",
      "Failed to retrieve dividend data\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Function to accept cookies\n",
    "def accept_cookies(driver):\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"Button__StyledButton-a1qza5-0.jkvvVr\")))\n",
    "        if accept_button:\n",
    "            accept_button.click()\n",
    "            print(\"Clicked Accept All Button\")\n",
    "        else:\n",
    "            print(\"Accept button not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking accept button: {e}\")\n",
    "\n",
    "# Function to scrape dividend data\n",
    "def scrape_dividend_data(url):\n",
    "    try:\n",
    "        # Get the page content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the page content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the relevant data using more specific selectors\n",
    "        main_div = soup.find('div', {'id': 'main_content'})\n",
    "        if not main_div:\n",
    "            print(\"Main div not found\")\n",
    "            return None\n",
    "        \n",
    "        dividend_data = {}\n",
    "        \n",
    "        # Extract the current dividend payout\n",
    "        payout_tag = main_div.find('meta', {'name': 'description'})\n",
    "        if payout_tag:\n",
    "            content = payout_tag.get('content')\n",
    "            if content:\n",
    "                # Assuming the format contains \"dividend payout for Linde (LIN) as of <date> is <strong>$5.56</strong>\"\n",
    "                start_str = \"dividend payout for Linde (LIN) as of\"\n",
    "                start_index = content.find(start_str)\n",
    "                if start_index != -1:\n",
    "                    data_str = content[start_index + len(start_str):].strip()\n",
    "                    dividend_data['dividend_payout'] = data_str.split(' ')[-1].strip()\n",
    "        \n",
    "        # Extract the current dividend yield\n",
    "        yield_tag = main_div.find('meta', {'name': 'description'})\n",
    "        if yield_tag:\n",
    "            content = yield_tag.get('content')\n",
    "            if content:\n",
    "                # Assuming the format contains \"dividend yield for Linde as of <date> is <strong>1.28%</strong>\"\n",
    "                start_str = \"dividend yield for Linde as of\"\n",
    "                start_index = content.find(start_str)\n",
    "                if start_index != -1:\n",
    "                    data_str = content[start_index + len(start_str):].strip()\n",
    "                    dividend_data['dividend_yield'] = data_str.split(' ')[-1].strip()\n",
    "        \n",
    "        if not dividend_data:\n",
    "            print(\"No data found for LIN\")\n",
    "        return dividend_data\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test URL\n",
    "url = 'https://www.macrotrends.net/stocks/charts/LIN/linde/dividend-yield-history'\n",
    "data = scrape_dividend_data(url)\n",
    "if data:\n",
    "    print(\"Dividend Data:\", data)\n",
    "else:\n",
    "    print(\"Failed to retrieve dividend data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
